---
title: "OFT"
output:
  pdf_document: default
  html_document: default
date: '2022-12-05'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Load data
```{r}
setwd("~/Documents/TDP control files/Longitudinal induction analysis/OFT/")
# Loading
library(pacman)
p_load(readxl, tidyverse)
p_load(broom, ggsignif, multcomp, emmeans, DescTools)
# xlsx files
df <- read_excel("OFT_longitudinal_data.xlsx")

```



We will look at two parameters:
- how much time mouse spent moving (absolute and relative to total time) (measure of exploration)
- how much time was spent on center compared to periphery (measure of anxiety, if anxious = more time spent in periphery)

Time spent moving:
```{r}
# divide by time not spent moving
df<-  df %>% mutate(relative_time_moving=(df$`Movement cumulative s`/(df$`Time not moving cumulative s`+df$`Movement cumulative s`))*100)
```

Periphery preference:

```{r}
df<-  df %>% mutate(periphery_preference=(`In zone periphery cumulative s`/(`In zone Center cumulative s`+`In zone periphery cumulative s`)*100))
```



Data set where participants not completing all data collection time points are sorted out

```{r}
# Determine the weeks each participant should have
required_weeks <- df %>% 
  distinct(Week) %>% 
  pull()

# Count the number of weeks each participant has data for
participant_week_counts <- df %>%
  group_by(ID) %>%
  summarize(week_count = n_distinct(Week))

# Identify participants with data for all required weeks
complete_participants <- participant_week_counts %>%
  filter(week_count == length(required_weeks)) %>%
  pull(ID)

# Filter the dataset to include only complete participants
df_complete <- df %>%
  filter(ID %in% complete_participants)

# View the new dataset
head(df_complete)
```

Assumption checks

```{r}

df_complete$ID <- as.factor(df_complete$ID)
df_complete$distance <- df_complete$`Distance moved cm`

p_load(rstatix)
#outliers - 3
df_complete %>%
  group_by(Week) %>%
  identify_outliers(distance)

#normality - holds
df_complete %>%
  group_by(Week) %>%
  shapiro_test(distance)

by(df_complete$distance, df_complete$Week, shapiro.test)

#sphericity - similar to the homogeneity of variance in between-group anova)
#sphericity not broken
anova_test(data = df_complete, dv = distance, wid = ID, within = Week)

#F Indicates that we are comparing to an F-distribution (F-test); (2, 18) indicates the degrees of freedom in the numerator (DFn) and the denominator (DFd), respectively; 55.5 indicates the obtained F-statistic value
#p specifies the p-value
#ges is the generalized effect size (amount of variability due to the within-subjects factor)
```


#Repeated measures ANOVA
```{r}
df_complete$ID <- as.factor(df_complete$ID)
df_complete$distance <- df_complete$`Distance moved cm`

df_complete$Week <- factor(df_complete$Week , levels = c("Preinduction","1st week post induction","2nd week post induction"))


#for getting an anova object that can be used for post-hoc
p_load(afex)
aov_anova <- aov_car(distance ~ Week+ Error(ID /Week), data=df_complete)
summary(aov_anova)

#post-hoc
p_load(emmeans)
ph<-emmeans(aov_anova, pairwise ~ Week, conf.level = 0.95, adjust = "tukey")
ph
confint(ph)  #for confidence intervals

test(ph) # for p values

#bonfferoni
posthoc_bonf <- emmeans(aov_anova, pairwise ~ Week, adjust = "bonferroni")
summary(posthoc_bonf)


```




```{r}
#Loading packages for linear mixed effects modelling
library(lmerTest)
library(lme4)

df$distance <- df$`Distance moved cm`

#creating a linear model of the same variables as included in the anova
m_anova <- lmer(distance ~ Week + (1 | ID), data = df)
summary(m_anova)

# Obtain estimated marginal means
emmeans_results <- emmeans(m_anova, ~ Week)

# Perform pairwise comparisons
pairwise_results <- contrast(emmeans_results, method = "pairwise", adjust = "tukey")

# Display the results
summary(pairwise_results)

#bonferroni
pwc <- pairs(emmeans_results, adjust = "bon")
pwc
```



```{r}
cbbPalette <- c("#fcfdbf", "#feca8d", "#D67236", "#f1605d", "#9e2f7f", "#440f76")

p_load(ggbeeswarm, ggsignif)

ggplot(df, aes(x = Week, y = distance)) +
  geom_beeswarm(data = df, size = 2.5, aes(color = ID)) +
#  geom_dotplot(aes(fill = ID, color = ID), binaxis = 'y', binwidth = 1,
#               method = "histodot", stackratio = 1, dotsize = 0.5,
#               stackgroups = TRUE, stackdir = "down", position = position_nudge(x = -.1)) +
#  scale_fill_manual(values = cbbPalette) +
#  scale_colour_manual(values = cbbPalette) +
  ylab("Distance (cm)") +
  xlab("Timepoint") +
  geom_signif(comparisons = list(c("Preinduction", "1st week post induction")),
              map_signif_level = TRUE,
              y_position = 8800,
              annotations = c("ns")) +
  geom_signif(comparisons = list(c("Preinduction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 8400,
              annotations = c("**")) +
  geom_signif(comparisons = list(c("1st week post induction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 8000,
              annotations = c("ns")) +
  geom_crossbar(stat = "summary", fun = mean, width = 0.2, fatten = 1.5) +
  geom_errorbar(data = df, stat = "summary", fun.data = mean_se, width = 0.1, position = "dodge") +
  theme(text = element_text(size = 13))

```

Periphery preference

Assumption checks
```{r}

df_complete$ID <- as.factor(df_complete$ID)

p_load(rstatix)
#outliers - 2
df_complete %>%
  group_by(Week) %>%
  identify_outliers(periphery_preference)

#normality - holds
df_complete %>%
  group_by(Week) %>%
  shapiro_test(periphery_preference)

by(df_complete$periphery_preference, df_complete$Week, shapiro.test)

#sphericity - similar to the homogeneity of variance in between-group anova)
#sphericity not broken
anova_test(data = df_complete, dv = periphery_preference, wid = ID, within = Week)

#F Indicates that we are comparing to an F-distribution (F-test); (2, 18) indicates the degrees of freedom in the numerator (DFn) and the denominator (DFd), respectively; 55.5 indicates the obtained F-statistic value
#p specifies the p-value
#ges is the generalized effect size (amount of variability due to the within-subjects factor)
```

#Repeated measures ANOVA
```{r}

aov_anova <- aov_car(periphery_preference ~ Week+ Error(ID /Week), data=df_complete)
summary(aov_anova)

#post-hoc
p_load(emmeans)
ph<-emmeans(aov_anova, pairwise ~ Week, conf.level = 0.95)
ph
confint(ph)  #for confidence intervals

test(ph) # for p values

```


plot

```{r}
cbbPalette <- c("#fcfdbf", "#feca8d", "#D67236", "#f1605d", "#9e2f7f", "#440f76")

p_load(ggbeeswarm, ggsignif)

ggplot(df_complete, aes(x = Week, y = periphery_preference)) +
  geom_beeswarm(data = df_complete, size = 2.5, aes(color = ID)) +
#  geom_dotplot(aes(fill = ID, color = ID), binaxis = 'y', binwidth = 1,
#               method = "histodot", stackratio = 1, dotsize = 0.5,
#               stackgroups = TRUE, stackdir = "down", position = position_nudge(x = -.1)) +
#  scale_fill_manual(values = cbbPalette) +
#  scale_colour_manual(values = cbbPalette) +
  ylab("periphery preference") +
  xlab("Timepoint") +
  geom_signif(comparisons = list(c("Preinduction", "1st week post induction")),
              map_signif_level = TRUE,
              y_position = 110,
              annotations = c("**")) +
  geom_signif(comparisons = list(c("Preinduction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 105,
              annotations = c("**")) +
  geom_signif(comparisons = list(c("1st week post induction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 100,
              annotations = c("ns")) +
  geom_crossbar(stat = "summary", fun = mean, width = 0.2, fatten = 1.5) +
  geom_errorbar(data = df_complete, stat = "summary", fun.data = mean_se, width = 0.1, position = "dodge") +
  theme(text = element_text(size = 13))

```
ORIGINAL ANALYSIS

Distance moved

#Assumption checks
The repeated measures ANOVA makes the following assumptions about the data:

No significant outliers in any cell of the design. This can be checked by visualizing the data using box plot methods and by using the function identify_outliers() [rstatix package].
Normality: the outcome (or dependent) variable should be approximately normally distributed in each cell of the design. This can be checked using the Shapiro-Wilk normality test (shapiro_test() [rstatix]) or by visual inspection using QQ plot (ggqqplot() [ggpubr package]).
Assumption of sphericity: the variance of the differences between groups should be equal. This can be checked using the Mauchlyâ€™s test of sphericity, which is automatically reported when using the R function anova_test() [rstatix package]. Read more in Chapter @ref(mauchly-s-test-of-sphericity-in-r).

```{r}

df$ID <- as.factor(df$ID)
df$distance <- df$`Distance moved cm`

p_load(rstatix)
#outliers - 3
df %>%
  group_by(Week) %>%
  identify_outliers(distance)

#normality - holds
df %>%
  group_by(Week) %>%
  shapiro_test(distance)

by(df$distance, df$Week, shapiro.test)

#sphericity - similar to the homogeneity of variance in between-group anova)
#sphericity not broken
anova_test(data = df, dv = distance, wid = ID, within = Week)

#F Indicates that we are comparing to an F-distribution (F-test); (2, 18) indicates the degrees of freedom in the numerator (DFn) and the denominator (DFd), respectively; 55.5 indicates the obtained F-statistic value
#p specifies the p-value
#ges is the generalized effect size (amount of variability due to the within-subjects factor)
```


#Repeated measures ANOVA
```{r}
df$ID <- as.factor(df$ID)
df$distance <- df$`Distance moved cm`

df$Week <- factor(df$Week , levels = c("Preinduction","1st week post induction","2nd week post induction"))


#for getting an anova object that can be used for post-hoc
p_load(afex)
aov_anova <- aov_car(distance ~ Week+ Error(ID /Week), data=df)
summary(aov_anova)

#post-hoc
p_load(emmeans)
ph<-emmeans(aov_anova, pairwise ~ Week, conf.level = 0.95)
ph
confint(ph)  #for confidence intervals

test(ph) # for p values


```


```{r}
#Loading packages for linear mixed effects modelling
library(lmerTest)
library(lme4)

#creating a linear model of the same variables as included in the anova
m_anova <-lmer(periphery_preference ~  Week + (1|ID), data=df)
summary(m_anova)

# Obtain estimated marginal means
emmeans_results <- emmeans(m_anova, ~ Week)

# Perform pairwise comparisons
pairwise_results <- contrast(emmeans_results, method = "pairwise")

# Display the results
summary(pairwise_results)

#bonferroni
pwc <- pairs(emmeans_results, adjust = "bon")
pwc
```

```{r}
cbbPalette <- c("#fcfdbf", "#feca8d", "#D67236", "#f1605d", "#9e2f7f", "#440f76")

p_load(ggbeeswarm, ggsignif)

ggplot(df, aes(x = Week, y = periphery_preference)) +
  geom_beeswarm(data = df, size = 2.5, aes(color = ID)) +
#  geom_dotplot(aes(fill = ID, color = ID), binaxis = 'y', binwidth = 1,
#               method = "histodot", stackratio = 1, dotsize = 0.5,
#               stackgroups = TRUE, stackdir = "down", position = position_nudge(x = -.1)) +
#  scale_fill_manual(values = cbbPalette) +
#  scale_colour_manual(values = cbbPalette) +
  ylab("periphery preference") +
  xlab("Timepoint") +
  geom_signif(comparisons = list(c("Preinduction", "1st week post induction")),
              map_signif_level = TRUE,
              y_position = 110,
              annotations = c("***")) +
  geom_signif(comparisons = list(c("Preinduction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 105,
              annotations = c("***")) +
  geom_signif(comparisons = list(c("1st week post induction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 100,
              annotations = c("ns")) +
  geom_crossbar(stat = "summary", fun = mean, width = 0.2, fatten = 1.5) +
  geom_errorbar(data = df, stat = "summary", fun.data = mean_se, width = 0.1, position = "dodge") +
  theme(text = element_text(size = 13))

```

Assumption checks for this approach

```{r}
#1. normality of residuals
# Fit the model
m_anova <- lmer(periphery_preference ~ Week + (1|ID), data = df, na.action = na.omit)

# Extract residuals
residuals <- residuals(m_anova)

# Q-Q plot for normality
qqnorm(residuals)
qqline(residuals)

#2. homoscedasticity (the same as homogeneity of variance)
# Residuals vs Fitted plot
plot(fitted(m_anova), residuals)
abline(h = 0, col = "red")


#3. Independence of Residuals

#Since this is a repeated measures design, you have accounted for within-subject correlation by including random effects. Ensure that there are no obvious patterns in the residuals versus time.

#4 Random Effects Structure:

#The random effects (e.g., intercepts and slopes for each subject) should be normally distributed. This can be checked by examining the distribution of the random effects.

# Extract random effects
ranef(m_anova)

# Check distribution of random effects
qqnorm(ranef(m_anova)$ID[,1])
qqline(ranef(m_anova)$ID[,1])

#5 Linearity:

#The relationship between the predictor variables and the response variable should be linear. This can be assessed by plotting the fitted values against the predictor variables.

# Plot fitted values vs predictors
plot(df$Week, fitted(m_anova))


```

Handling Violations
If any of the assumptions are violated, consider the following:

Transformations: Transform the response variable (e.g., log transformation) to address non-normality or heteroscedasticity.
Alternative Models: Use generalized linear mixed models (GLMMs) if the response variable does not meet normality assumptions.
Robust Standard Errors: Use robust standard errors to adjust for heteroscedasticity.
Imputation Methods: Ensure proper handling of missing data, especially if the data is not MAR.

Friedman test
```{r}
friedman.test(y = df$distance, groups = df$Week, blocks = df$ID)

```
```{r}
# Rename columns if necessary to match the format for pivoting
colnames(df) <- c("ID", "Preinduction", "X1st.week.post.induction", "X2nd.week.post.induction")

# Convert to long format
df_long <- pivot_longer(df, cols = starts_with("X"), names_to = "Week", values_to = "value")

# Remove any rows with missing values
df_long <- na.omit(df_long)

# Run the Friedman test
friedman.test(value ~ Week | ID, data = df_long)

```

#Repeated measures ANOVA
```{r}

aov_anova <- aov_car(periphery_preference ~ Week+ Error(ID /Week), data=df)
summary(aov_anova)

#post-hoc
p_load(emmeans)
ph<-emmeans(aov_anova, pairwise ~ Week, conf.level = 0.95)
ph
confint(ph)  #for confidence intervals

test(ph) # for p values

```



```{r}
#Loading packages for linear mixed effects modelling
library(lmerTest)
library(lme4)

#creating a linear model of the same variables as included in the anova
m_anova <-lmer(periphery_preference ~  Week + (1|ID), data=df)
summary(m_anova)

# Obtain estimated marginal means
emmeans_results <- emmeans(m_anova, ~ Week)

# Perform pairwise comparisons
pairwise_results <- contrast(emmeans_results, method = "pairwise")

# Display the results
summary(pairwise_results)

#bonferroni
pwc <- pairs(emmeans_results, adjust = "bon")
pwc
```

plot

```{r}
cbbPalette <- c("#fcfdbf", "#feca8d", "#D67236", "#f1605d", "#9e2f7f", "#440f76")

p_load(ggbeeswarm, ggsignif)

ggplot(df, aes(x = Week, y = periphery_preference)) +
  geom_beeswarm(data = df, size = 2.5, aes(color = ID)) +
#  geom_dotplot(aes(fill = ID, color = ID), binaxis = 'y', binwidth = 1,
#               method = "histodot", stackratio = 1, dotsize = 0.5,
#               stackgroups = TRUE, stackdir = "down", position = position_nudge(x = -.1)) +
#  scale_fill_manual(values = cbbPalette) +
#  scale_colour_manual(values = cbbPalette) +
  ylab("periphery preference") +
  xlab("Timepoint") +
  geom_signif(comparisons = list(c("Preinduction", "1st week post induction")),
              map_signif_level = TRUE,
              y_position = 110,
              annotations = c("** (0.005)")) +
  geom_signif(comparisons = list(c("Preinduction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 105,
              annotations = c("*** (<0.0001)")) +
  geom_signif(comparisons = list(c("1st week post induction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 100,
              annotations = c("ns (0.2539)")) +
  geom_crossbar(stat = "summary", fun = mean, width = 0.2, fatten = 1.5) +
  geom_errorbar(data = df, stat = "summary", fun.data = mean_se, width = 0.1, position = "dodge") +
  theme(text = element_text(size = 13))

```